================================================================================
2. VIDEO DATASET PARAMETERS
================================================================================

VideoDataset Class Parameters:
------------------------------
video_paths             = (required list)            # List of paths to video files
labels                  = (required list)            # List of labels corresponding to videos
num_frames              = 32                         # Number of frames to extract per video
image_size              = 224                        # Image size (height and width)
cache_size              = 100                        # Maximum number of videos to cache in memory


================================================================================
3. DATA LOADING & SPLITTING
================================================================================

Data Split Ratios:
-----------------
Train Set               = 90% (0.95 * 0.9474 = ~90%)
Validation Set          = 5%  (0.95 * 0.0526 = ~5%)
Test Set                = 5%  (0.05 directly)
random_state            = 42                         # Random seed for reproducibility
stratify                = True                       # Stratified split by class


================================================================================
4. MODEL ARCHITECTURE PARAMETERS
================================================================================

HuggingFace ViViT (Primary):
----------------------------
Model                   = "google/vivit-b-16x2-kinetics400"
num_labels              = len(data_subset)           # Automatically set based on dataset
num_frames              = 32                         # Inherited from pretrained config
image_size              = 224                        # Inherited from pretrained config
tubelet_size            = [2, 16, 16]                # Temporal, Height, Width
patch_size (spatial)    = 16x16                      # Spatial patch size
tubelet_size (temporal) = 2                          # Temporal tubelet size

Custom ViViT (Fallback):
------------------------
image_size              = 224                        # Input image size
patch_size              = 16                         # Patch size for patch embedding
num_classes             = len(data_subset)           # Number of output classes
num_frames              = 32                         # Number of frames per video
dropout                 = 0.2                        # Dropout rate
emb_dropout             = 0.1                        # Embedding dropout rate
depth                   = 4                          # Number of transformer layers (Space)


================================================================================
5. TRAINING HYPERPARAMETERS
================================================================================

Optimizer (AdamW):
-----------------
optimizer               = optim.AdamW
learning_rate           = 1e-3                       # Initial learning rate
weight_decay            = 1e-2                       # L2 regularization weight decay

Loss Function:
-------------
criterion               = nn.CrossEntropyLoss
label_smoothing         = 0.1                        # Label smoothing for regularization

Learning Rate Scheduler:
-----------------------
scheduler               = ReduceLROnPlateau
mode                    = 'min'                      # Reduce LR when validation loss stops decreasing
factor                  = 0.5                        # LR reduction factor (new_lr = lr * factor)
patience                = 10                         # Number of epochs with no improvement before reducing LR
min_lr                  = 1e-6                       # Minimum learning rate

Gradient Clipping:
-----------------
max_norm                = 1.0                        # Maximum gradient norm for clipping

Training Loop:
-------------
additional_epochs       = 200                        # Number of epochs to train
early_stopping_patience = 20                         # Stop if no improvement for N epochs
start_epoch             = 0                          # Starting epoch (0 for new training)


================================================================================
6. PRETRAINED WEIGHTS & TRANSFER LEARNING
================================================================================

Pretrained Model Loading:
------------------------
pretrained_path         = None                       # Path to local pretrained weights (optional)
num_classes_pretrained  = 101                        # Number of classes in pretrained model
num_classes_current     = 14                         # Number of classes in current dataset

HuggingFace Model:
-----------------
ignore_mismatched_sizes = True                       # Allow loading with different num_classes

Layer Freezing (Custom ViViT):
------------------------------
Freeze: to_patch_embedding parameters
Freeze: pos_embedding (nn.Parameter)
Freeze: space_token (nn.Parameter)
Freeze: temporal_token (nn.Parameter)
Freeze: entire space_transformer (all 4 layers by default)

Optional temporal layer freezing (commented out):
num_temporal_layers_to_freeze = 3                    # First N temporal transformer layers



================================================================================
9. METRICS & EVALUATION
================================================================================

Metrics Calculated:
------------------
Overall Metrics:
- accuracy
- precision_macro (macro-averaged precision)
- recall_macro (macro-averaged recall)
- f1_macro (macro-averaged F1)
- precision_micro (micro-averaged precision)
- recall_micro (micro-averaged recall)
- f1_micro (micro-averaged F1)
- precision_weighted (weighted-averaged precision)
- recall_weighted (weighted-averaged recall)
- f1_weighted (weighted-averaged F1)

Per-Class Metrics:
- accuracy (per class)
- precision (per class)
- recall (per class)
- f1 (per class)

Inference Time Tracking:
-----------------------
- Per-video inference time (seconds)
- Average, Min, Max, Median, Std Dev
- Saved to CSV with predictions

Metrics Saved As:
----------------
- detailed_metrics.txt
- metrics.csv
- per_class_f1.png (bar plot)
- confusion_matrix.png (heatmap)
- classification_report_detailed.csv
- inference_times.csv
- inference_time_distribution.png (histogram)


================================================================================
10. PLOTTING & VISUALIZATION PARAMETERS
================================================================================

Plots Generated:
---------------
Training Metrics:
- loss_plot.png (train vs val loss)
- accuracy_plot.png (train vs val accuracy)
- precision_plot.png (train vs val precision)
- recall_plot.png (train vs val recall)
- f1_plot.png (train vs val F1)
- classwise_evolution.png (per-class F1 evolution over epochs)

Test Metrics:
- confusion_matrix_detailed.png
- classwise_performance.png (precision, recall, F1 per class)
- inference_time_distribution.png

================================================================================
16. ADDITIONAL NOTES
================================================================================

Regularization Techniques:
-------------------------
- Label smoothing (0.1)
- Weight decay (1e-2)
- Gradient clipping (max_norm=1.0)
- Dropout (0.2 in custom ViViT)
- Embedding dropout (0.1 in custom ViViT)
- Early stopping (patience=20)
